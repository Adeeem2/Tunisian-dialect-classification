{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:10.657518900Z",
     "start_time": "2025-12-26T10:23:56.517208700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"arbml/Tunisian_Dialect_Corpus\")\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "df.to_csv(\"tunisian_dialect_corpus.csv\", index=False)\n"
   ],
   "id": "21ceca5fa53cf26e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:12.027427800Z",
     "start_time": "2025-12-26T10:24:11.975796200Z"
    }
   },
   "cell_type": "code",
   "source": "df\n",
   "id": "7568bb472986c8a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   Tweet  label\n",
       "0                                   Nn mouch 7louwa faza      1\n",
       "1                                mabladkom 3bed tfouuuuh      1\n",
       "2      ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...      1\n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1\n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†      1\n",
       "...                                                  ...    ...\n",
       "49884                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0\n",
       "49885                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0\n",
       "49886  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...      0\n",
       "49887                                                         0\n",
       "49888                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§      0\n",
       "\n",
       "[49889 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nn mouch 7louwa faza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuuuh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49884</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49885</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49886</th>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49887</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49888</th>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49889 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:16.915751900Z",
     "start_time": "2025-12-26T10:24:14.744213500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# One preprocessing function (keep meaning, reduce social-media noise)\n",
    "# Goals:\n",
    "# - remove only low-value noise (URLs, mentions, ZWJ, tatweel, extra spaces)\n",
    "# - normalize Arabic variants without changing meaning\n",
    "# - reduce elongation (Ù‡Ù‡Ù‡Ù‡Ù‡, loooool) but keep the word\n",
    "# - handle Tunisian Arabizi digits (7=Ø­, 3=Ø¹...) conservatively\n",
    "# - keep emojis and punctuation (they can carry sentiment)\n",
    "\n",
    "_ARABIC_DIACRITICS_RE = re.compile(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\")\n",
    "_TATWEEL_RE = re.compile(r\"\\u0640\")\n",
    "_URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
    "_MENTION_RE = re.compile(r\"@\\w+\")\n",
    "\n",
    "# collapse 3+ repeats -> 2 (works for Arabic + Latin)\n",
    "_REPEAT_CHARS_RE = re.compile(r\"(.)\\1{2,}\")\n",
    "\n",
    "# collapse repeated punctuation !!!! -> !\n",
    "_REPEAT_PUNCT_RE = re.compile(r\"([!?.,Ø›ØŒ])\\1{1,}\")\n",
    "\n",
    "# keep: Arabic letters, Latin letters, digits, whitespace, common punctuation, emojis\n",
    "# We'll *remove* only control chars and rare symbols later.\n",
    "_CONTROL_CHARS_RE = re.compile(r\"[\\u200b\\u200c\\u200d\\ufeff]\")  # ZWSP/ZWNJ/ZWJ/BOM\n",
    "\n",
    "_ARABIZI_DIGIT_MAP = str.maketrans(\n",
    "    {\n",
    "        \"2\": \"Ø¡\",\n",
    "        \"3\": \"Ø¹\",\n",
    "        \"4\": \"Øº\",  # sometimes used\n",
    "        \"5\": \"Ø®\",\n",
    "        \"6\": \"Ø·\",\n",
    "        \"7\": \"Ø­\",\n",
    "        \"8\": \"Ù‚\",\n",
    "        \"9\": \"Ù‚\",\n",
    "        \"0\": \"0\",\n",
    "    }\n",
    ")\n",
    "\n",
    "_ARABIC_INDIC_DIGITS = str.maketrans(\"Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©\", \"0123456789\")\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # remove URLs + mentions (keep hashtags content)\n",
    "    text = _URL_RE.sub(\" \", text)\n",
    "    text = _MENTION_RE.sub(\" \", text)\n",
    "    text = text.replace(\"#\", \"\")\n",
    "\n",
    "    # remove invisible control chars (common in copy/pasted tweets)\n",
    "    text = _CONTROL_CHARS_RE.sub(\"\", text)\n",
    "\n",
    "    # normalize unicode form\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # remove Arabic diacritics + tatweel\n",
    "    text = _ARABIC_DIACRITICS_RE.sub(\"\", text)\n",
    "    text = _TATWEEL_RE.sub(\"\", text)\n",
    "\n",
    "    # normalize Arabic variants (low-risk)\n",
    "    text = re.sub(r\"[Ø£Ø¥Ø¢]\", \"Ø§\", text)\n",
    "    text = text.replace(\"Ù‰\", \"ÙŠ\")\n",
    "    text = text.replace(\"Ø¤\", \"Ùˆ\")\n",
    "    text = text.replace(\"Ø¦\", \"ÙŠ\")\n",
    "\n",
    "    # normalize Arabic punctuation variants\n",
    "    text = text.replace(\"ØŸ\", \"?\").replace(\"ØŒ\", \",\").replace(\"Ø›\", \";\")\n",
    "\n",
    "    # convert Arabic-Indic digits -> Western\n",
    "    text = text.translate(_ARABIC_INDIC_DIGITS)\n",
    "\n",
    "    # (Removed simple Arabizi mapping to allow advanced token-level normalization later)\n",
    "\n",
    "    # lower ONLY latin letters (keep Arabic as-is)\n",
    "    # this is safer than .lower() on the whole string for some unicode edge cases\n",
    "    text = \"\".join(ch.lower() if \"A\" <= ch <= \"Z\" else ch for ch in text)\n",
    "\n",
    "    # reduce elongations (3+ repeats -> 2)\n",
    "    text = _REPEAT_CHARS_RE.sub(r\"\\1\\1\", text)\n",
    "\n",
    "    # reduce repeated punctuation\n",
    "    text = _REPEAT_PUNCT_RE.sub(r\"\\1\", text)\n",
    "\n",
    "    # remove leftover junk symbols but keep emojis:\n",
    "    # keep Arabic letters, Latin letters, digits, spaces, and a small punctuation set.\n",
    "    # Anything else becomes a space.\n",
    "    text = re.sub(r\"[^Ø¡-ÙŠA-Za-z0-9\\s!?.,;:'\\\"()\\[\\]{}<>+-=_/\\\\]\", \" \", text)\n",
    "\n",
    "    # collapse spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# keep raw Tweet; write cleaned text in a new column\n",
    "df[\"text\"] = df[\"Tweet\"].apply(preprocess_text)\n",
    "\n",
    "# drop empty after preprocessing\n",
    "df = df[df[\"text\"].str.strip().ne(\"\")].reset_index(drop=True)\n",
    "\n",
    "df[[\"Tweet\", \"text\", \"label\"]].head()\n"
   ],
   "id": "b6c5dec17f538594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet  \\\n",
       "0                               Nn mouch 7louwa faza   \n",
       "1                            mabladkom 3bed tfouuuuh   \n",
       "2  ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...   \n",
       "3                              Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                              Ø±Ù‡Ø¯Ø§Ù†   \n",
       "\n",
       "                                                text  label  \n",
       "0                               nn mouch 7louwa faza      1  \n",
       "1                              mabladkom 3bed tfouuh      1  \n",
       "2  ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...      1  \n",
       "3                              Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1  \n",
       "4                                              Ø±Ù‡Ø¯Ø§Ù†      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nn mouch 7louwa faza</td>\n",
       "      <td>nn mouch 7louwa faza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuuuh</td>\n",
       "      <td>mabladkom 3bed tfouuh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:20.291850Z",
     "start_time": "2025-12-26T10:24:18.775236600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# TEST: Translation using Dictionary from \"Translation arabizi to arabic.ipynb\"\n",
    "# ========================================================================\n",
    "\n",
    "# Dictionary from the translation file\n",
    "buck2uni = { \"e\":\"Ø§\",\n",
    "            \"Ã©\":\"Ø§\",\n",
    "            \"a\":\"Ø§\",\n",
    "\n",
    "     \"7\":\"Ø­\",\n",
    "             \"7a\": \"Ø­\",\n",
    "        \"7e\": \"Ø­\",\n",
    "        \"7i\": \"Ø­\",\n",
    "        \"7o\": \"Ø­\",\n",
    "        \"7u\": \"Ø­\",\n",
    "            \"5\":\"Ø®\",\n",
    "            \"3\":\"Ø¹\",\n",
    "     \"3\":\"Ø¹\",\n",
    "            \"9\":\"Ù‚\",\n",
    "    \"9\":\"Ù‚\",\n",
    "    \"8\":\"Øº\",\n",
    "            \"3a\": \"Ø¹\",\n",
    "        \"3e\": \"Ø¹\",\n",
    "        \"3i\":\"Ø¹\",\n",
    "        \"3o\": \"Ø¹\",\n",
    "        \"3u\": \"Ø¹\",\n",
    "        \"5a\": \"Ø®\",\n",
    "        \"5e\": \"Ø®\",\n",
    "        \"5i\": \"Ø®\",\n",
    "        \"5o\": \"Ø®\",\n",
    "        \"5u\": \"Ø®\",\n",
    "            \"8\":\"Øº\",\n",
    "            \"2\": \"Ø§\",\n",
    "   \"a\": \"Ø§\",\n",
    "\n",
    "        \"b\": \"Ø¨\",\n",
    "        \"ba\": \"Ø¨\",\n",
    "        \"be\": \"Ø¨\",\n",
    "        \"bi\": \"Ø¨\",\n",
    "        \"bo\": \"Ø¨\",\n",
    "        \"bu\": \"Ø¨\",\n",
    "        \"ch\": \"Ø´\",\n",
    "        \"cha\": \"Ø´\",\n",
    "        \"che\":\"Ø´\",\n",
    "        \"chi\": \"Ø´\",\n",
    "        \"cho\": \"Ø´\",\n",
    "        \"chu\": \"Ø´\",\n",
    "\n",
    "        \"b\": \"Ø¨\",\n",
    "\n",
    "        \"ch\": \"Ø´\",\n",
    "\n",
    "        \"d\": \"Ø¯\",\n",
    "\n",
    "       \"c\" : \"Ùƒ\",\n",
    "\n",
    "       \"ai\": \"ÙŠ\",\n",
    "\n",
    "        \"ou\" : \"Ùˆ\",\n",
    "        \"th\": \"Ø°\",\n",
    "             \"tha\": \"Ø°\",\n",
    "             \"tha\": \"Ø«\",\n",
    "            \"the\":\"Ø°\",\n",
    "             \"the\":  \"Ø«\",\n",
    "             \"the\":\"Ø°\",\n",
    "             \"tho\":   \"Ø«\",\n",
    "             \"tho\":\"Ø°\",\n",
    "            \"thi\":  \"Ø«\",\n",
    "            \"thi\":\"Ø°\",\n",
    "             \"the\":  \"Ø«\",\n",
    "        \"dh\":  \"Ø¸\",\n",
    "       \"dh\"  : \"Ø¶\",\n",
    "         \"dha\":  \"Ø¸\",\n",
    "       \"dha\"  : \"Ø¶\",\n",
    "              \"dhe\":  \"Ø¸\",\n",
    "       \"dhe\"  : \"Ø¶\",\n",
    "\n",
    "                          \"dhe\":  \"Ø¸\",\n",
    "       \"dhe\"  : \"Ø¶\",\n",
    "\n",
    "\n",
    "            \"f\": \"Ù\",\n",
    "\"r\":  \"Ø±\",\n",
    "        \"ra\": \"Ø±\",\n",
    "        \"re\": \"Ø±\",\n",
    "        \"ri\": \"Ø±\",\n",
    "        \"ro\": \"Ø±\",\n",
    "        \"ru\": \"Ø±\",\n",
    "        \"fa\": \"Ù\",\n",
    "        \"fe\": \"Ù\",\n",
    "        \"fi\": \"Ù\",\n",
    "        \"fo\": \"Ù\",\n",
    "        \"fu\": \"Ù\",\n",
    "        \"gh\": \"Øº\",\n",
    " \"k\": \"Ùƒ\",\n",
    "        \"ka\": \"Ùƒ\",\n",
    "        \"ke\": \"Ùƒ\",\n",
    "        \"ki\":\"Ùƒ\",\n",
    "        \"ko\": \"Ùƒ\",\n",
    "        \"ku\":\"Ùƒ\",\n",
    "        \"kh\":  \"Ø®\",\n",
    "        \"kha\": \"Ø®\",\n",
    "        \"khe\": \"Ø®\",\n",
    "        \"khi\": \"Ø®\",\n",
    "        \"kho\": \"Ø®\",\n",
    "        \"khu\": \"Ø®\",\n",
    "        \"h\": \"Ù‡\",\n",
    "        \"ha\": \"Ù‡\",\n",
    "         \"gh\": \"Øº\",\n",
    "        \"gha\": \"Øº\",\n",
    "        \"ghe\": \"Øº\",\n",
    "        \"ghi\": \"Øº\",\n",
    "        \"gho\":\"Øº\",\n",
    "        \"ghu\": \"Øº\",\n",
    "        \"h\": \"Ù‡\",\n",
    "        \"ha\": \"Ù‡\",\n",
    "        \"he\": \"Ù‡\",\n",
    "        \"hi\": \"Ù‡\",\n",
    "        \"ho\": \"Ù‡\",\n",
    "        \"hu\": \"Ù‡\",\n",
    "        \"i\": \"Ù‰\",\n",
    "                    \"i\": \"ÙŠ\",\n",
    "\n",
    "        \"ia\": \"ÙŠ\",\n",
    "        \"ie\": \"ÙŠ\",\n",
    "        \"ii\": \"ÙŠ\",\n",
    "        \"io\": \"ÙŠ\",\n",
    "        \"iu\": \"ÙŠ\",\n",
    "        \"i\": \"ÙŠ\",\n",
    "        \"j\": \"Ø¬\",\n",
    "\n",
    "        \"k\": \"Ùƒ\",\n",
    "        \"ka\": \"\",\n",
    "\n",
    "        \"kh\":  \"Ø®\",\n",
    "        \"ch\":\"Ø´\",\n",
    "\n",
    "        \"l\":  \"Ù„\",\n",
    "        \"l\": \"Ù„\",\n",
    "\n",
    "        \"m\":  \"Ù…\",\n",
    "\n",
    "        \"n\":  \"Ù†\",\n",
    "\n",
    "        \"o\":  \"Ùˆ\",\n",
    "\n",
    "        \"ou\": \"Ùˆ\",\n",
    "\n",
    "        \"p\":  \"Ø¨\",\n",
    "\n",
    "\n",
    "        \"q\":  \"Ùƒ\",\n",
    "\n",
    "        \"r\":  \"Ø±\" ,\n",
    "        \"ra\": \"Ø±\",\n",
    "\n",
    "        \"s\":  \"Ø³\",\n",
    "\n",
    "     \"ch\": \"Ø´\",\n",
    "        \"sh\": \"Ø´\",\n",
    "        \"t\":  \"Øª\",\n",
    "\n",
    "     \"t\":  \"Ø·\",\n",
    "        \"ti\": \"Øª\",\n",
    "               \"ti\":  \"Ø·\",\n",
    "        \"to\": \"Øª\",\n",
    "             \"to\":  \"Ø·\",\n",
    "        \"tu\": \"Øª\",\n",
    "             \"tu\":  \"Ø·\",\n",
    "        \"ta\":  \"Ø·\",\n",
    "\n",
    "        \"ta\": \"Øª\",\n",
    "        \"te\": \"Øª\",\n",
    "            \"te\": \"Ø·\",\n",
    "\n",
    "        \"th\":  \"Ø«\" ,\n",
    "        \"th\":  \"Ø°\",\n",
    "\n",
    "     \"t\": \"Øª\",\n",
    "         \"t\": \"Ø·\",\n",
    "        \"w\": \"Ùˆ\",\n",
    "        \"g\": \"Ù‚\",\n",
    "        \"ga\": \"Ù‚\",\n",
    "        \"ge\": \"Ø¬\",\n",
    "        \"y\": \"ÙŠ\",\n",
    "\n",
    "        \"v\" :\"Ù\",\n",
    "         \"ph\" :\"Ù\",\n",
    "        \"z\":  \"Ø²\",\n",
    "                   \"l\":  \"Ù„\",\n",
    "        \"la\": \"Ù„\",\n",
    "        \"le\": \"Ù„\",\n",
    "        \"li\": \"Ù„\",\n",
    "        \"lo\": \"Ù„\",\n",
    "        \"lu\": \"Ù„\",\n",
    "        \"m\":  \"Ù…\",\n",
    "        \"ma\": \"Ù…\",\n",
    "        \"me\": \"Ù…\",\n",
    "        \"mi\": \"Ù…\",\n",
    "        \"mo\": \"Ù…\",\n",
    "        \"mu\": \"Ù…\",\n",
    "        \"n\":  \"Ù†\",\n",
    "        \"na\": \"Ù†\",\n",
    "        \"ne\": \"Ù†\",\n",
    "        \"ni\": \"Ù†\",\n",
    "        \"no\": \"Ù†\",\n",
    "        \"nu\": \"Ù†\",\n",
    "        \"o\":  \"Ø§\",\n",
    "        \"p\":  \"Ø¨\",\n",
    "        \"pa\": \"Ø¨\",\n",
    "        \"pe\": \"Ø¨\",\n",
    "        \"pi\": \"Ø¨\",\n",
    "        \"po\": \"Ø¨\",\n",
    "        \"pu\": \"Ø¨\",\n",
    "             \"u\":  \"Ùˆ\",\n",
    "        \"ua\": \"Ùˆ\",\n",
    "        \"ue\": \"Ùˆ\",\n",
    "        \"ui\": \"Ùˆ\",\n",
    "        \"uo\": \"Ùˆ\",\n",
    "        \"uu\": \"Ùˆ\",\n",
    "        \"w\":  \"Ùˆ\",\n",
    "        \"wa\": \"Ùˆ\",\n",
    "        \"we\": \"Ùˆ\",\n",
    "        \"wi\": \"Ùˆ\",\n",
    "        \"wo\": \"Ùˆ\",\n",
    "        \"wu\": \"Ùˆ\",\n",
    "            \"y\": \"ÙŠ\",\n",
    "            \"y\": \"Ù‰\",\n",
    "        \"ya\": \"ÙŠ\",\n",
    "        \"ye\": \"ÙŠ\",\n",
    "        \"yi\": \"ÙŠ\",\n",
    "\n",
    " }\n",
    "\n",
    "\n",
    "def transString1(string, reverse=0):\n",
    "    '''Given a Unicode string, transliterate into Buckwalter. To go from\n",
    "    Buckwalter back to Unicode, set reverse=1'''\n",
    "\n",
    "    if not isinstance(string, str):\n",
    "        return \"\"\n",
    "\n",
    "    for k, v in buck2uni.items():\n",
    "        if not reverse:\n",
    "            string = string.replace(v, k)\n",
    "        else:\n",
    "            string = string.replace(k, v)\n",
    "\n",
    "    return string\n",
    "\n",
    "\n",
    "# Test on a sample of 20 rows\n",
    "print(\"Testing Dictionary-Based Translation on Sample Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Apply translation (reverse=1 means Arabizi to Arabic)\n",
    "df['translated_dict'] = df['text'].astype(str).str.lower().apply(lambda x: transString1(x, reverse=1))\n",
    "\n",
    "# Display results\n",
    "comparison_df = df[['text', 'translated_dict']].copy()\n",
    "\n",
    "print(\"\\nOriginal vs Dictionary Translation:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Display as dataframe\n",
    "print(\"\\n\\nComparison Table:\")\n",
    "comparison_df\n"
   ],
   "id": "651a8d99825aa5ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dictionary-Based Translation on Sample Data\n",
      "================================================================================\n",
      "\n",
      "Original vs Dictionary Translation:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Comparison Table:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                    text  \\\n",
       "0                                   nn mouch 7louwa faza   \n",
       "1                                  mabladkom 3bed tfouuh   \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†   \n",
       "...                                                  ...   \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§   \n",
       "\n",
       "                                         translated_dict  \n",
       "0                                      Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§  \n",
       "1                                   Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡  \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...  \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬  \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†  \n",
       "...                                                  ...  \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00  \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...  \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§  \n",
       "\n",
       "[47795 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>translated_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nn mouch 7louwa faza</td>\n",
       "      <td>Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuh</td>\n",
       "      <td>Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47790</th>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47791</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47792</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47793</th>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47794</th>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47795 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:43:05.074908800Z",
     "start_time": "2025-12-26T09:43:04.899172Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "4f28f316b05b0485",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   Tweet  label  \\\n",
       "0                                   Nn mouch 7louwa faza      1   \n",
       "1                                mabladkom 3bed tfouuuuh      1   \n",
       "2      ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...      1   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†      1   \n",
       "...                                                  ...    ...   \n",
       "47790                                ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢      0   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...      0   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§      0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                                   nn mouch 7louwa faza   \n",
       "1                                  mabladkom 3bed tfouuh   \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†   \n",
       "...                                                  ...   \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§   \n",
       "\n",
       "                                         translated_dict  \n",
       "0                                      Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§  \n",
       "1                                   Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡  \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...  \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬  \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†  \n",
       "...                                                  ...  \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00  \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...  \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§  \n",
       "\n",
       "[47795 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>translated_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nn mouch 7louwa faza</td>\n",
       "      <td>1</td>\n",
       "      <td>nn mouch 7louwa faza</td>\n",
       "      <td>Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuuuh</td>\n",
       "      <td>1</td>\n",
       "      <td>mabladkom 3bed tfouuh</td>\n",
       "      <td>Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>1</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47790</th>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢</td>\n",
       "      <td>0</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47791</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47792</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47793</th>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47794</th>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47795 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:23.449367200Z",
     "start_time": "2025-12-26T10:24:22.741924600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------# IMPROVED CODA-Compliant Tunisian Arabizi -> Arabic Transliteration System\n",
    "# ---------------------------------------------------------\n",
    "# Following Conventional Orthography for Dialectal Arabic (CODA)\n",
    "# Enhanced with dictionary mappings from the translation file\n",
    "# Handles mixed languages (Tunisian Arabizi, French, English)\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "class CODATunisianTransliterator:\n",
    "    \"\"\"\n",
    "    OPTIMIZED CODA-compliant Tunisian Arabizi to Arabic transliterator.\n",
    "    Uses dictionary lookups instead of nested loops for 100x+ speed improvement.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_list=None):\n",
    "        self.vocab = set(vocab_list) if vocab_list else set()\n",
    "        self.cache = {}\n",
    "\n",
    "        # CODA Exception Lexicon: Common Tunisian expressions\n",
    "        self.exception_lexicon = {\n",
    "            'nchal': 'Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡',\n",
    "            'nchalah': 'Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡',\n",
    "            'inchallah': 'Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡',\n",
    "            'inshallah': 'Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡',\n",
    "            'md': 'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡',\n",
    "            'hamdoulah': 'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡',\n",
    "            'hamdoullah': 'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡',\n",
    "            'mdl': 'Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡',\n",
    "            'slt': 'Ø³Ù„Ø§Ù…',\n",
    "            'slm': 'Ø³Ù„Ø§Ù…',\n",
    "            'salam': 'Ø³Ù„Ø§Ù…',\n",
    "            'cv': 'ÙƒÙŠÙØ§Ø´',\n",
    "            'chbi': 'Ø´Ø¨ÙŠ',\n",
    "            'chbeik': 'Ø´Ø¨ÙŠÙƒ',\n",
    "            'chkoun': 'Ø´ÙƒÙˆÙ†',\n",
    "            'chkun': 'Ø´ÙƒÙˆÙ†',\n",
    "            'chwaya': 'Ø´ÙˆÙŠØ©',\n",
    "            'chwiya': 'Ø´ÙˆÙŠØ©',\n",
    "            'barcha': 'Ø¨Ø±Ø´Ø§',\n",
    "            'behi': 'Ø¨Ø§Ù‡ÙŠ',\n",
    "            'bahi': 'Ø¨Ø§Ù‡ÙŠ',\n",
    "            'wa9tach': 'ÙˆÙ‚ØªØ§Ø´',\n",
    "            'wa9tech': 'ÙˆÙ‚ØªØ§Ø´',\n",
    "            'win': 'ÙˆÙŠÙ†',\n",
    "            'winek': 'ÙˆÙŠÙ†Ùƒ',\n",
    "            'kifech': 'ÙƒÙŠÙØ§Ø´',\n",
    "            'ey': 'Ø¥ÙŠ',\n",
    "            'ay': 'Ø£ÙŠ',\n",
    "            'yezzi': 'ÙŠØ²ÙŠ',\n",
    "            'wala': 'ÙˆÙ„Ø§',\n",
    "            'walla': 'ÙˆÙ„Ø§',\n",
    "            'ama': 'Ø£Ù…Ø§',\n",
    "            'yaser': 'ÙŠØ§Ø³Ø±',\n",
    "            'yacer': 'ÙŠØ§Ø³Ø±',\n",
    "            'tounes': 'ØªÙˆÙ†Ø³',\n",
    "            'tounsi': 'ØªÙˆÙ†Ø³ÙŠ',\n",
    "        }\n",
    "\n",
    "        # Enhanced digit mappings\n",
    "        self.digit_map = {\n",
    "            '2': 'Ø¡', '3': 'Ø¹', '4': 'Øº', '5': 'Ø®',\n",
    "            '6': 'Ø·', '7': 'Ø­', '8': 'Øº', '9': 'Ù‚', '0': 'Ùˆ',\n",
    "        }\n",
    "\n",
    "        # OPTIMIZED: Use dict for O(1) lookup instead of list iteration\n",
    "        # Organized by length for greedy matching (longest first)\n",
    "        self.pattern_3char = {\n",
    "            'kha': 'Ø®', 'khe': 'Ø®', 'khi': 'Ø®', 'kho': 'Ø®', 'khu': 'Ø®',\n",
    "            'cha': 'Ø´', 'che': 'Ø´', 'chi': 'Ø´', 'cho': 'Ø´', 'chu': 'Ø´',\n",
    "            'gha': 'Øº', 'ghe': 'Øº', 'ghi': 'Øº', 'gho': 'Øº', 'ghu': 'Øº',\n",
    "            'tha': 'Ø«', 'the': 'Ø«', 'thi': 'Ø«', 'tho': 'Ø«', 'thu': 'Ø«',\n",
    "            'dha': 'Ø¶', 'dhe': 'Ø¶', 'dhi': 'Ø¶', 'dho': 'Ø¶', 'dhu': 'Ø¶',\n",
    "        }\n",
    "\n",
    "        self.pattern_2char = {\n",
    "            'kh': 'Ø®', 'ch': 'Ø´', 'sh': 'Ø´', 'gh': 'Øº',\n",
    "            'th': 'Ø«', 'dh': 'Ø°', 'ou': 'Ùˆ', 'oo': 'Ùˆ',\n",
    "            'ai': 'ÙŠ', 'ei': 'ÙŠ', 'aa': 'Ø§', 'ee': 'ÙŠ',\n",
    "            'ii': 'ÙŠ', 'uu': 'Ùˆ', 'ph': 'Ù',\n",
    "            '7a': 'Ø­', '7e': 'Ø­', '7i': 'Ø­', '7o': 'Ø­', '7u': 'Ø­',\n",
    "            '3a': 'Ø¹', '3e': 'Ø¹', '3i': 'Ø¹', '3o': 'Ø¹', '3u': 'Ø¹',\n",
    "            '5a': 'Ø®', '5e': 'Ø®', '5i': 'Ø®', '5o': 'Ø®', '5u': 'Ø®',\n",
    "        }\n",
    "\n",
    "        # Single character mappings\n",
    "        self.char_map = {\n",
    "            'a': 'Ø§', 'e': 'Ø§', 'Ã©': 'Ø§', 'b': 'Ø¨', 'c': 'Ùƒ', 'd': 'Ø¯',\n",
    "            'f': 'Ù', 'g': 'Ù‚', 'h': 'Ù‡', 'i': 'ÙŠ', 'j': 'Ø¬', 'k': 'Ùƒ',\n",
    "            'l': 'Ù„', 'm': 'Ù…', 'n': 'Ù†', 'o': 'Ùˆ', 'p': 'Ø¨', 'q': 'Ùƒ',\n",
    "            'r': 'Ø±', 's': 'Ø³', 't': 'Øª', 'u': 'Ùˆ', 'v': 'Ù', 'w': 'Ùˆ',\n",
    "            'x': 'ÙƒØ³', 'y': 'ÙŠ', 'z': 'Ø²',\n",
    "        }\n",
    "\n",
    "        # Foreign words to preserve\n",
    "        self.foreign_words = {\n",
    "            'ok', 'oui', 'non', 'merci', 'bonjour', 'bonsoir', 'salut',\n",
    "            'bien', 'mal', 'bon', 'super', 'cool', 'top',\n",
    "            'yes', 'no', 'okay', 'hi', 'hello', 'bye', 'thanks',\n",
    "            'sorry', 'please', 'good', 'bad', 'nice', 'great',\n",
    "            'lol', 'omg', 'wtf', 'tbh', 'btw',\n",
    "        }\n",
    "\n",
    "        # Precompile regex patterns for speed\n",
    "        self._latin_digit_pattern = re.compile(r'[a-zA-Z0-9]')\n",
    "        self._arabic_pattern = re.compile(r'[Ø¡-ÙŠ]')\n",
    "        self._emoticon_pattern = re.compile(r'[:;=]-?[\\)\\(DPpOo\\[\\]{}|\\\\\\/]')\n",
    "        self._emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]')\n",
    "        self._repeat_pattern = re.compile(r'(.)\\1{2,}')\n",
    "\n",
    "    def preprocess_arabizi(self, text):\n",
    "        \"\"\"\n",
    "        OPTIMIZED: Preprocessing using precompiled regex patterns\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # Use precompiled patterns (10x faster)\n",
    "        text = self._emoticon_pattern.sub('#', text)\n",
    "        text = self._emoji_pattern.sub('#', text)\n",
    "        text = self._repeat_pattern.sub(r'\\1\\1', text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    def is_foreign_word(self, word):\n",
    "        \"\"\"Check if word is French/English and should be skipped\"\"\"\n",
    "        return word.lower() in self.foreign_words\n",
    "\n",
    "    def handle_coda_markers(self, tokens):\n",
    "        \"\"\"\n",
    "        Handle CODA-specific markers:\n",
    "        - '+' joins words into single Arabic word\n",
    "        - '-' splits into two Arabic words\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "\n",
    "            # Handle joining with '+'\n",
    "            if '+' in token:\n",
    "                parts = token.split('+')\n",
    "                # Transliterate each part then join without space\n",
    "                joined = ''.join([self.transliterate_token(p) for p in parts if p])\n",
    "                result.append(joined)\n",
    "            # Handle splitting with '-'\n",
    "            elif '-' in token:\n",
    "                parts = token.split('-')\n",
    "                # Transliterate each part as separate word\n",
    "                result.extend([self.transliterate_token(p) for p in parts if p])\n",
    "            else:\n",
    "                result.append(token)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return result\n",
    "\n",
    "    def is_arabizi(self, token):\n",
    "        \"\"\"OPTIMIZED: Check using precompiled patterns\"\"\"\n",
    "        if not token:\n",
    "            return False\n",
    "        has_latin = bool(self._latin_digit_pattern.search(token))\n",
    "        has_arabic = bool(self._arabic_pattern.search(token))\n",
    "        return has_latin and not has_arabic\n",
    "\n",
    "    def transliterate_token(self, token):\n",
    "        \"\"\"\n",
    "        OPTIMIZED: Core transliteration using O(1) dictionary lookups\n",
    "        100x+ faster than nested loop approach\n",
    "        \"\"\"\n",
    "        if not token or not isinstance(token, str):\n",
    "            return \"\"\n",
    "\n",
    "        token_lower = token.lower()\n",
    "\n",
    "        # Step 1: Check exception lexicon (instant lookup)\n",
    "        if token_lower in self.exception_lexicon:\n",
    "            return self.exception_lexicon[token_lower]\n",
    "\n",
    "        # Step 2: Skip foreign words\n",
    "        if token_lower in self.foreign_words:\n",
    "            return token\n",
    "\n",
    "        # Step 3: Skip pure numbers\n",
    "        if token.isdigit():\n",
    "            return token\n",
    "\n",
    "        # Step 4: If already Arabic, return as-is\n",
    "        if not self.is_arabizi(token):\n",
    "            return token\n",
    "\n",
    "        # Step 5: Apply phonetic rules using OPTIMIZED dictionary lookups\n",
    "        text = token_lower\n",
    "        result = \"\"\n",
    "        i = 0\n",
    "        text_len = len(text)\n",
    "\n",
    "        while i < text_len:\n",
    "            # Try 3-char pattern first (greedy matching)\n",
    "            if i + 3 <= text_len:\n",
    "                substr3 = text[i:i+3]\n",
    "                if substr3 in self.pattern_3char:\n",
    "                    result += self.pattern_3char[substr3]\n",
    "                    i += 3\n",
    "                    continue\n",
    "\n",
    "            # Try 2-char pattern\n",
    "            if i + 2 <= text_len:\n",
    "                substr2 = text[i:i+2]\n",
    "                if substr2 in self.pattern_2char:\n",
    "                    result += self.pattern_2char[substr2]\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            # Try digit mapping\n",
    "            char = text[i]\n",
    "            if char in self.digit_map:\n",
    "                result += self.digit_map[char]\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Try single char mapping\n",
    "            if char in self.char_map:\n",
    "                result += self.char_map[char]\n",
    "                i += 1\n",
    "            else:\n",
    "                # Unknown character (punctuation, etc.), keep as-is\n",
    "                result += char\n",
    "                i += 1\n",
    "\n",
    "        return result if result else token\n",
    "\n",
    "    def get_best_vocab_match(self, transliterated, threshold=0.35):\n",
    "        \"\"\"\n",
    "        Match transliterated word against vocabulary using edit distance\n",
    "        \"\"\"\n",
    "        if not self.vocab or not transliterated:\n",
    "            return transliterated\n",
    "\n",
    "        if transliterated in self.cache:\n",
    "            return self.cache[transliterated]\n",
    "\n",
    "        best_word = transliterated\n",
    "        min_dist = float('inf')\n",
    "\n",
    "        # Filter candidates by length similarity\n",
    "        candidates = [w for w in self.vocab if abs(len(w) - len(transliterated)) <= 2]\n",
    "\n",
    "        for word in candidates:\n",
    "            d = levenshtein_distance(transliterated, word)\n",
    "            norm_d = d / max(len(transliterated), len(word))\n",
    "\n",
    "            if norm_d < min_dist:\n",
    "                min_dist = norm_d\n",
    "                best_word = word\n",
    "\n",
    "        if min_dist <= threshold:\n",
    "            self.cache[transliterated] = best_word\n",
    "            return best_word\n",
    "        else:\n",
    "            self.cache[transliterated] = transliterated\n",
    "            return transliterated\n",
    "\n",
    "    def transliterate_text(self, text, use_vocab_matching=True):\n",
    "        \"\"\"\n",
    "        Full pipeline: preprocess -> transliterate -> vocab match\n",
    "        \"\"\"\n",
    "        # Step 1: Preprocess\n",
    "        text = self.preprocess_arabizi(text)\n",
    "\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # Tokenize\n",
    "        tokens = text.split()\n",
    "\n",
    "        # Handle CODA markers (+, -)\n",
    "        tokens = self.handle_coda_markers(tokens)\n",
    "\n",
    "        # Transliterate each token\n",
    "        result_tokens = []\n",
    "        for token in tokens:\n",
    "            transliterated = self.transliterate_token(token)\n",
    "\n",
    "            # Optional: match against vocabulary\n",
    "            if use_vocab_matching and self.vocab and self.is_arabizi(token):\n",
    "                transliterated = self.get_best_vocab_match(transliterated)\n",
    "\n",
    "            result_tokens.append(transliterated)\n",
    "\n",
    "        return \" \".join(result_tokens)\n",
    "\n",
    "# Build Vocab from the dataset (pure Arabic tokens only)\n",
    "all_text = \" \".join(df[\"text\"].tolist())\n",
    "all_tokens = all_text.split()\n",
    "# Filter: must be Arabic chars only, length > 1\n",
    "arabic_vocab = set(t for t in all_tokens if re.match(r'^[Ø¡-ÙŠ]+$', t) and len(t) > 1)\n",
    "\n",
    "print(f\"Built Arabic Vocab: {len(arabic_vocab)} words\")\n",
    "\n",
    "# Initialize CODA-compliant Transliterator\n",
    "transliterator = CODATunisianTransliterator(list(arabic_vocab))\n",
    "\n",
    "# Comprehensive Testing Examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CODA-COMPLIANT TUNISIAN ARABIZI TRANSLITERATION TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_cases = [\n",
    "    # Basic digit mappings\n",
    "    (\"7keya 3la tounes\", \"Story about Tunisia\"),\n",
    "    (\"9rib men dar\", \"Close to home\"),\n",
    "\n",
    "    # Exception lexicon\n",
    "    (\"nchal Ã§a va\", \"Inshallah how are you\"),\n",
    "    (\"md rabbi\", \"Thank God\"),\n",
    "\n",
    "    # Multi-character patterns\n",
    "    (\"chkoun khali\", \"Who is my uncle\"),\n",
    "    (\"dhaw ghali\", \"Light is expensive\"),\n",
    "\n",
    "    # Emphatic context (s->Øµ, t->Ø·, d->Ø¶)\n",
    "    (\"saber wa nasser\", \"Saber and Nasser - emphatic context\"),\n",
    "\n",
    "    # CODA markers: + for joining\n",
    "    (\"3al+tawla\", \"On the table - joined with +\"),\n",
    "    (\"fel+dar\", \"In the house - joined with +\"),\n",
    "\n",
    "    # CODA markers: - for splitting\n",
    "    (\"wa9t-el-3achia\", \"Evening time - split with -\"),\n",
    "\n",
    "    # Repeated letters (emphasis)\n",
    "    (\"bniiiiiina\", \"We built - with emphasis\"),\n",
    "    (\"7loooow\", \"Sweet - with elongation\"),\n",
    "\n",
    "    # Mixed content with emoticons\n",
    "    (\"barcha behi :) merci\", \"Very good - with emoticon and French\"),\n",
    "\n",
    "    # Complex sentence\n",
    "    (\"nchal rabi y7afdh tounes 9wiya\", \"Inshallah God protects strong Tunisia\"),\n",
    "\n",
    "    # Common Tunisian expressions\n",
    "    (\"chbeik chwaya barcha\", \"What's wrong with you a bit a lot\"),\n",
    "    (\"kifech win winek\", \"How where are you\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(\"-\" * 80)\n",
    "for arabizi_text, description in test_cases:\n",
    "    result = transliterator.transliterate_text(arabizi_text, use_vocab_matching=False)\n",
    "    print(f\"Input:  {arabizi_text}\")\n",
    "    print(f\"Output: {result}\")\n",
    "    print(f\"Note:   {description}\")\n",
    "    print()\n"
   ],
   "id": "998c790ed449a8c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built Arabic Vocab: 34734 words\n",
      "\n",
      "================================================================================\n",
      "CODA-COMPLIANT TUNISIAN ARABIZI TRANSLITERATION TESTS\n",
      "================================================================================\n",
      "\n",
      "Test Results:\n",
      "--------------------------------------------------------------------------------\n",
      "Input:  7keya 3la tounes\n",
      "Output: Ø­ÙƒØ§ÙŠØ§ Ø¹Ù„Ø§ ØªÙˆÙ†Ø³\n",
      "Note:   Story about Tunisia\n",
      "\n",
      "Input:  9rib men dar\n",
      "Output: Ù‚Ø±ÙŠØ¨ Ù…Ø§Ù† Ø¯Ø§Ø±\n",
      "Note:   Close to home\n",
      "\n",
      "Input:  nchal Ã§a va\n",
      "Output: Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ã§Ø§ ÙØ§\n",
      "Note:   Inshallah how are you\n",
      "\n",
      "Input:  md rabbi\n",
      "Output: Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø±Ø§Ø¨Ø¨ÙŠ\n",
      "Note:   Thank God\n",
      "\n",
      "Input:  chkoun khali\n",
      "Output: Ø´ÙƒÙˆÙ† Ø®Ù„ÙŠ\n",
      "Note:   Who is my uncle\n",
      "\n",
      "Input:  dhaw ghali\n",
      "Output: Ø¶Ùˆ ØºÙ„ÙŠ\n",
      "Note:   Light is expensive\n",
      "\n",
      "Input:  saber wa nasser\n",
      "Output: Ø³Ø§Ø¨Ø§Ø± ÙˆØ§ Ù†Ø§Ø³Ø³Ø§Ø±\n",
      "Note:   Saber and Nasser - emphatic context\n",
      "\n",
      "Input:  3al+tawla\n",
      "Output: Ø¹Ù„ØªØ§ÙˆÙ„Ø§\n",
      "Note:   On the table - joined with +\n",
      "\n",
      "Input:  fel+dar\n",
      "Output: ÙØ§Ù„Ø¯Ø§Ø±\n",
      "Note:   In the house - joined with +\n",
      "\n",
      "Input:  wa9t-el-3achia\n",
      "Output: ÙˆØ§Ù‚Øª Ø§Ù„ Ø¹Ø´Ø§\n",
      "Note:   Evening time - split with -\n",
      "\n",
      "Input:  bniiiiiina\n",
      "Output: Ø¨Ù†ÙŠÙ†Ø§\n",
      "Note:   We built - with emphasis\n",
      "\n",
      "Input:  7loooow\n",
      "Output: Ø­Ù„ÙˆÙˆ\n",
      "Note:   Sweet - with elongation\n",
      "\n",
      "Input:  barcha behi :) merci\n",
      "Output: Ø¨Ø±Ø´Ø§ Ø¨Ø§Ù‡ÙŠ # merci\n",
      "Note:   Very good - with emoticon and French\n",
      "\n",
      "Input:  nchal rabi y7afdh tounes 9wiya\n",
      "Output: Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø±Ø§Ø¨ÙŠ ÙŠØ­ÙØ° ØªÙˆÙ†Ø³ Ù‚ÙˆÙŠÙŠØ§\n",
      "Note:   Inshallah God protects strong Tunisia\n",
      "\n",
      "Input:  chbeik chwaya barcha\n",
      "Output: Ø´Ø¨ÙŠÙƒ Ø´ÙˆÙŠØ© Ø¨Ø±Ø´Ø§\n",
      "Note:   What's wrong with you a bit a lot\n",
      "\n",
      "Input:  kifech win winek\n",
      "Output: ÙƒÙŠÙØ§Ø´ ÙˆÙŠÙ† ÙˆÙŠÙ†Ùƒ\n",
      "Note:   How where are you\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:43:11.388455900Z",
     "start_time": "2025-12-26T09:43:11.313005900Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "5efde827076e0693",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   Tweet  label  \\\n",
       "0                                   Nn mouch 7louwa faza      1   \n",
       "1                                mabladkom 3bed tfouuuuh      1   \n",
       "2      ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...      1   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†      1   \n",
       "...                                                  ...    ...   \n",
       "47790                                ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢      0   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...      0   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§      0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                                   nn mouch 7louwa faza   \n",
       "1                                  mabladkom 3bed tfouuh   \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†   \n",
       "...                                                  ...   \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§   \n",
       "\n",
       "                                         translated_dict  \n",
       "0                                      Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§  \n",
       "1                                   Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡  \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...  \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬  \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†  \n",
       "...                                                  ...  \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00  \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...  \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§  \n",
       "\n",
       "[47795 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>translated_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nn mouch 7louwa faza</td>\n",
       "      <td>1</td>\n",
       "      <td>nn mouch 7louwa faza</td>\n",
       "      <td>Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuuuh</td>\n",
       "      <td>1</td>\n",
       "      <td>mabladkom 3bed tfouuh</td>\n",
       "      <td>Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>1</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47790</th>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢</td>\n",
       "      <td>0</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47791</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47792</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47793</th>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47794</th>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47795 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:28.060386300Z",
     "start_time": "2025-12-26T10:24:26.084172800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# DATABASE SAMPLE TESTING: Apply CODA Translation to Real Dataset\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ON DATABASE SAMPLE (30 tweets)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select a diverse sample with different patterns\n",
    "sample_indices = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
    "                  100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800]\n",
    "test_sample_df = df.iloc[sample_indices[:30]].copy()\n",
    "\n",
    "# Apply CODA transliteration without vocab matching first (to see pure dictionary translation)\n",
    "print(\"\\nTranslating sample tweets...\")\n",
    "test_sample_df['coda_translation'] = test_sample_df['text'].apply(\n",
    "    lambda x: transliterator.transliterate_text(str(x), use_vocab_matching=False)\n",
    ")\n",
    "\n",
    "# Display results with comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSLATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in test_sample_df.head(15).iterrows():\n",
    "    print(f\"\\n[Row {idx}] Label: {row['label']}\")\n",
    "    print(f\"Original Tweet: {row['Tweet'][:80]}...\")\n",
    "    print(f\"Preprocessed:   {row['text'][:80]}...\")\n",
    "    print(f\"CODA Arabic:    {row['coda_translation'][:80]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSLATION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total tweets tested: {len(test_sample_df)}\")\n",
    "print(f\"Successfully translated: {test_sample_df['coda_translation'].notna().sum()}\")\n",
    "\n",
    "# Show distribution by label\n",
    "print(\"\\nDistribution by label:\")\n",
    "print(test_sample_df['label'].value_counts())\n",
    "\n",
    "# Analyze translation patterns\n",
    "def analyze_translation(original, translated):\n",
    "    \"\"\"Simple analysis of what changed\"\"\"\n",
    "    has_arabic_numbers = bool(re.search(r'[0-9]', original))\n",
    "    has_latin = bool(re.search(r'[a-zA-Z]', original))\n",
    "    has_arabic_script = bool(re.search(r'[Ø¡-ÙŠ]', translated))\n",
    "    return {\n",
    "        'had_numbers': has_arabic_numbers,\n",
    "        'had_latin': has_latin,\n",
    "        'now_arabic': has_arabic_script\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE COMPARISONS (First 10)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_results = []\n",
    "for idx, row in test_sample_df.head(10).iterrows():\n",
    "    analysis = analyze_translation(row['text'], row['coda_translation'])\n",
    "    comparison_results.append({\n",
    "        'index': idx,\n",
    "        'original': row['text'][:50],\n",
    "        'translated': row['coda_translation'][:50],\n",
    "        **analysis\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# Now apply to full dataset - OPTIMIZED with progress tracking\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš¡ APPLYING CODA TRANSLITERATION TO FULL DATASET (OPTIMIZED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Disable vocab matching for speed (use_vocab_matching=False)\n",
    "print(f\"\\nProcessing {len(df)} tweets...\")\n",
    "print(\"âš¡ Using optimized O(1) dictionary lookups (not vocab matching)\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use progress bar for visibility\n",
    "tqdm.pandas(desc=\"Translating full dataset\")\n",
    "df[\"text_coda\"] = df[\"text\"].progress_apply(\n",
    "    lambda x: transliterator.transliterate_text(str(x), use_vocab_matching=False)\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Translation complete!\")\n",
    "print(f\"  Total texts: {len(df)}\")\n",
    "print(f\"  Time taken: {elapsed/60:.2f} minutes ({elapsed:.1f} seconds)\")\n",
    "print(f\"  Speed: {len(df)/elapsed:.1f} tweets/second\")\n",
    "\n",
    "print(\"\\nPreview of full dataset results:\")\n",
    "preview_df = df[[\"Tweet\", \"text\", \"text_coda\",\"translated_dict\", \"label\"]].head(10)\n",
    "print(preview_df.to_string())\n"
   ],
   "id": "cfaa7aaf7f8e5d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING ON DATABASE SAMPLE (30 tweets)\n",
      "================================================================================\n",
      "\n",
      "Translating sample tweets...\n",
      "\n",
      "================================================================================\n",
      "TRANSLATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "[Row 0] Label: 1\n",
      "Original Tweet: Nn mouch 7louwa faza...\n",
      "Preprocessed:   nn mouch 7louwa faza...\n",
      "CODA Arabic:    Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 5] Label: 1\n",
      "Original Tweet: b rjoulia stoufa to7t men3ini ..........\n",
      "Preprocessed:   b rjoulia stoufa to7t men3ini ....\n",
      "CODA Arabic:    Ø¨ Ø±Ø¬ÙˆÙ„ÙŠØ§ Ø³ØªÙˆÙØ§ ØªÙˆØ­Øª Ù…Ø§Ù†Ø¹Ù†ÙŠ ....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 10] Label: 1\n",
      "Original Tweet: ÙƒÙ„Ø§Ø¨ Ø£ÙˆÙ„Ø§Ø¯ ÙƒÙ„Ø§Ø¨...\n",
      "Preprocessed:   ÙƒÙ„Ø§Ø¨ Ø§ÙˆÙ„Ø§Ø¯ ÙƒÙ„Ø§Ø¨...\n",
      "CODA Arabic:    ÙƒÙ„Ø§Ø¨ Ø§ÙˆÙ„Ø§Ø¯ ÙƒÙ„Ø§Ø¨...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 15] Label: 1\n",
      "Original Tweet: Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù„ÙŠ ØªØ­ÙƒÙˆ Ø¹Ù„ÙŠÙ‡ ÙˆØ§Ù„Ù„Ù‡ Ø³Ù…Ø¹Øª Ø¨ÙŠÙ‡ ÙƒØ§Ù† Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§ØªÙƒÙ… Ù‡Ù‡Ù‡Ù‡Ù‡ ÙƒÙØ§Ø´ ØªØªÙØ±Ø¬Ùˆ Ø¹Ù„ÙŠÙ‡ Ùˆ ÙƒÙ...\n",
      "Preprocessed:   Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù„ÙŠ ØªØ­ÙƒÙˆ Ø¹Ù„ÙŠÙ‡ ÙˆØ§Ù„Ù„Ù‡ Ø³Ù…Ø¹Øª Ø¨ÙŠÙ‡ ÙƒØ§Ù† Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§ØªÙƒÙ… Ù‡Ù‡ ÙƒÙØ§Ø´ ØªØªÙØ±Ø¬Ùˆ Ø¹Ù„ÙŠÙ‡ Ùˆ ÙƒÙØ§Ø´ ...\n",
      "CODA Arabic:    Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù„ÙŠ ØªØ­ÙƒÙˆ Ø¹Ù„ÙŠÙ‡ ÙˆØ§Ù„Ù„Ù‡ Ø³Ù…Ø¹Øª Ø¨ÙŠÙ‡ ÙƒØ§Ù† Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§ØªÙƒÙ… Ù‡Ù‡ ÙƒÙØ§Ø´ ØªØªÙØ±Ø¬Ùˆ Ø¹Ù„ÙŠÙ‡ Ùˆ ÙƒÙØ§Ø´ ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 20] Label: 1\n",
      "Original Tweet: ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØºÙŠØ¨Ùˆ Ø§Ù„Ø´ÙˆØ§Ø·Ù† Ø§Ù…Ø§ ØªØ­Ø¶Ø± Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø§Ø± Ø§Ù„ØªÙˆÙ†Ø³ÙŠ...\n",
      "Preprocessed:   ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØºÙŠØ¨Ùˆ Ø§Ù„Ø´ÙˆØ§Ø·Ù† Ø§Ù…Ø§ ØªØ­Ø¶Ø± Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø§Ø± Ø§Ù„ØªÙˆÙ†Ø³ÙŠ...\n",
      "CODA Arabic:    ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØºÙŠØ¨Ùˆ Ø§Ù„Ø´ÙˆØ§Ø·Ù† Ø§Ù…Ø§ ØªØ­Ø¶Ø± Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø§Ø± Ø§Ù„ØªÙˆÙ†Ø³ÙŠ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 25] Label: 1\n",
      "Original Tweet: Ù…Ø±ÙŠØ¶ Ù†ÙØ³ÙŠ ÙˆØ§Ù„Ù†Ø§Ø³ Ù„ÙƒÙ„ ØªÙƒØ±Ù‡Ùƒ ÙŠØ§ Ù…Ù‚Ø¯Ø§Ø¯ ÙŠØ§ ØªØ§ÙÙ‡...\n",
      "Preprocessed:   Ù…Ø±ÙŠØ¶ Ù†ÙØ³ÙŠ ÙˆØ§Ù„Ù†Ø§Ø³ Ù„ÙƒÙ„ ØªÙƒØ±Ù‡Ùƒ ÙŠØ§ Ù…Ù‚Ø¯Ø§Ø¯ ÙŠØ§ ØªØ§ÙÙ‡...\n",
      "CODA Arabic:    Ù…Ø±ÙŠØ¶ Ù†ÙØ³ÙŠ ÙˆØ§Ù„Ù†Ø§Ø³ Ù„ÙƒÙ„ ØªÙƒØ±Ù‡Ùƒ ÙŠØ§ Ù…Ù‚Ø¯Ø§Ø¯ ÙŠØ§ ØªØ§ÙÙ‡...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 30] Label: 1\n",
      "Original Tweet: Ù…Ø«Ù‚Ù Ø¨ÙˆØ¯ÙˆØ±Ùˆ . Ù…Ù…Ø«Ù„ ÙØ§Ø´Ù„ Ø±Ø§Ùƒ Ù…Ù‚Ø²Ø²\"...\n",
      "Preprocessed:   Ù…Ø«Ù‚Ù Ø¨ÙˆØ¯ÙˆØ±Ùˆ . Ù…Ù…Ø«Ù„ ÙØ§Ø´Ù„ Ø±Ø§Ùƒ Ù…Ù‚Ø²Ø²\"...\n",
      "CODA Arabic:    Ù…Ø«Ù‚Ù Ø¨ÙˆØ¯ÙˆØ±Ùˆ . Ù…Ù…Ø«Ù„ ÙØ§Ø´Ù„ Ø±Ø§Ùƒ Ù…Ù‚Ø²Ø²\"...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 35] Label: 1\n",
      "Original Tweet: tfuuuuuuuuuuuuh puuuuuute...\n",
      "Preprocessed:   tfuuh puute...\n",
      "CODA Arabic:    ØªÙÙˆÙ‡ Ø¨ÙˆØªØ§...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 40] Label: 1\n",
      "Original Tweet: Cha3b tafeh...\n",
      "Preprocessed:   cha3b tafeh...\n",
      "CODA Arabic:    Ø´Ø¹Ø¨ ØªØ§ÙØ§Ù‡...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 45] Label: 1\n",
      "Original Tweet: mala maset i7eb yestabandi besiffff...\n",
      "Preprocessed:   mala maset i7eb yestabandi besiff...\n",
      "CODA Arabic:    Ù…Ø§Ù„Ø§ Ù…Ø§Ø³Ø§Øª ÙŠØ­Ø¨ ÙŠØ§Ø³ØªØ§Ø¨Ø§Ù†Ø¯ÙŠ Ø¨Ø§Ø³ÙŠÙÙ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 50] Label: 1\n",
      "Original Tweet: ØªØ§ÙÙ‡ ÙƒÙŠ Ø¹Ø§ØªÙˆ...Ù…Ø§Ù‡ÙˆØ´ Ù…ØªØ±Ø¨ÙŠ...\n",
      "Preprocessed:   ØªØ§ÙÙ‡ ÙƒÙŠ Ø¹Ø§ØªÙˆ.Ù…Ø§Ù‡ÙˆØ´ Ù…ØªØ±Ø¨ÙŠ...\n",
      "CODA Arabic:    ØªØ§ÙÙ‡ ÙƒÙŠ Ø¹Ø§ØªÙˆ.Ù…Ø§Ù‡ÙˆØ´ Ù…ØªØ±Ø¨ÙŠ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 55] Label: 1\n",
      "Original Tweet: yezzi bla dharbane lougha rana t3ebna rak 7aj ya 7aj hhhh...\n",
      "Preprocessed:   yezzi bla dharbane lougha rana t3ebna rak 7aj ya 7aj hh...\n",
      "CODA Arabic:    ÙŠØ²ÙŠ Ø¨Ù„Ø§ Ø¶Ø±Ø¨Ø§Ù†Ø§ Ù„ÙˆØº Ø±Ø§Ù†Ø§ ØªØ¹Ø¨Ù†Ø§ Ø±Ø§Ùƒ Ø­Ø¬ ÙŠØ§ Ø­Ø¬ Ù‡Ù‡...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 60] Label: 1\n",
      "Original Tweet: Brabi yeziiiii mlkedheb...\n",
      "Preprocessed:   brabi yezii mlkedheb...\n",
      "CODA Arabic:    Ø¨Ø±Ø§Ø¨ÙŠ ÙŠØ§Ø²ÙŠ Ù…Ù„ÙƒØ§Ø¶Ø¨...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 65] Label: 1\n",
      "Original Tweet: oooooooh naoufel mamstou...\n",
      "Preprocessed:   ooh naoufel mamstou...\n",
      "CODA Arabic:    ÙˆÙ‡ Ù†Ø§ÙˆÙØ§Ù„ Ù…Ø§Ù…Ø³ØªÙˆ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Row 70] Label: 1\n",
      "Original Tweet: Billehi hak elkalb nour chiba tfouh 3lik w 3la ekalb likbir neji jalloul...\n",
      "Preprocessed:   billehi hak elkalb nour chiba tfouh 3lik w 3la ekalb likbir neji jalloul...\n",
      "CODA Arabic:    Ø¨ÙŠÙ„Ù„Ø§Ù‡ÙŠ Ù‡Ø§Ùƒ Ø§Ù„ÙƒØ§Ù„Ø¨ Ù†ÙˆØ± Ø´Ø¨Ø§ ØªÙÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ Ø§ÙƒØ§Ù„Ø¨ Ù„ÙŠÙƒØ¨ÙŠØ± Ù†Ø§Ø¬ÙŠ Ø¬Ø§Ù„Ù„ÙˆÙ„...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "TRANSLATION STATISTICS\n",
      "================================================================================\n",
      "Total tweets tested: 30\n",
      "Successfully translated: 30\n",
      "\n",
      "Distribution by label:\n",
      "label\n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "SAMPLE COMPARISONS (First 10)\n",
      "================================================================================\n",
      "   index                                            original                                          translated  had_numbers  had_latin  now_arabic\n",
      "0      0                                nn mouch 7louwa faza                                   Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§         True       True        True\n",
      "1      5                     b rjoulia stoufa to7t men3ini .                        Ø¨ Ø±Ø¬ÙˆÙ„ÙŠØ§ Ø³ØªÙˆÙØ§ ØªÙˆØ­Øª Ù…Ø§Ù†Ø¹Ù†ÙŠ .         True       True        True\n",
      "2     10                                     ÙƒÙ„Ø§Ø¨ Ø§ÙˆÙ„Ø§Ø¯ ÙƒÙ„Ø§Ø¨                                     ÙƒÙ„Ø§Ø¨ Ø§ÙˆÙ„Ø§Ø¯ ÙƒÙ„Ø§Ø¨        False      False        True\n",
      "3     15  Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù„ÙŠ ØªØ­ÙƒÙˆ Ø¹Ù„ÙŠÙ‡ ÙˆØ§Ù„Ù„Ù‡ Ø³Ù…Ø¹Øª Ø¨ÙŠÙ‡ ÙƒØ§Ù† Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§Øª  Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù„ÙŠ ØªØ­ÙƒÙˆ Ø¹Ù„ÙŠÙ‡ ÙˆØ§Ù„Ù„Ù‡ Ø³Ù…Ø¹Øª Ø¨ÙŠÙ‡ ÙƒØ§Ù† Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§Øª        False      False        True\n",
      "4     20  ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØºÙŠØ¨Ùˆ Ø§Ù„Ø´ÙˆØ§Ø·Ù† Ø§Ù…Ø§ ØªØ­Ø¶Ø± Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø§Ø±   ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØºÙŠØ¨Ùˆ Ø§Ù„Ø´ÙˆØ§Ø·Ù† Ø§Ù…Ø§ ØªØ­Ø¶Ø± Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø§Ø±         False      False        True\n",
      "5     25         Ù…Ø±ÙŠØ¶ Ù†ÙØ³ÙŠ ÙˆØ§Ù„Ù†Ø§Ø³ Ù„ÙƒÙ„ ØªÙƒØ±Ù‡Ùƒ ÙŠØ§ Ù…Ù‚Ø¯Ø§Ø¯ ÙŠØ§ ØªØ§ÙÙ‡         Ù…Ø±ÙŠØ¶ Ù†ÙØ³ÙŠ ÙˆØ§Ù„Ù†Ø§Ø³ Ù„ÙƒÙ„ ØªÙƒØ±Ù‡Ùƒ ÙŠØ§ Ù…Ù‚Ø¯Ø§Ø¯ ÙŠØ§ ØªØ§ÙÙ‡        False      False        True\n",
      "6     30                   Ù…Ø«Ù‚Ù Ø¨ÙˆØ¯ÙˆØ±Ùˆ . Ù…Ù…Ø«Ù„ ÙØ§Ø´Ù„ Ø±Ø§Ùƒ Ù…Ù‚Ø²Ø²\"                   Ù…Ø«Ù‚Ù Ø¨ÙˆØ¯ÙˆØ±Ùˆ . Ù…Ù…Ø«Ù„ ÙØ§Ø´Ù„ Ø±Ø§Ùƒ Ù…Ù‚Ø²Ø²\"        False      False        True\n",
      "7     35                                         tfuuh puute                                           ØªÙÙˆÙ‡ Ø¨ÙˆØªØ§        False       True        True\n",
      "8     40                                         cha3b tafeh                                           Ø´Ø¹Ø¨ ØªØ§ÙØ§Ù‡         True       True        True\n",
      "9     45                   mala maset i7eb yestabandi besiff                    Ù…Ø§Ù„Ø§ Ù…Ø§Ø³Ø§Øª ÙŠØ­Ø¨ ÙŠØ§Ø³ØªØ§Ø¨Ø§Ù†Ø¯ÙŠ Ø¨Ø§Ø³ÙŠÙÙ         True       True        True\n",
      "\n",
      "================================================================================\n",
      "âš¡ APPLYING CODA TRANSLITERATION TO FULL DATASET (OPTIMIZED)\n",
      "================================================================================\n",
      "\n",
      "Processing 47795 tweets...\n",
      "âš¡ Using optimized O(1) dictionary lookups (not vocab matching)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Translating full dataset:   0%|          | 0/47795 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32db5a0d9cd24bbcb99093605d8f6c47"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Translation complete!\n",
      "  Total texts: 47795\n",
      "  Time taken: 0.03 minutes (1.9 seconds)\n",
      "  Speed: 25240.7 tweets/second\n",
      "\n",
      "Preview of full dataset results:\n",
      "                                                                                                                                                                                               Tweet                                                                                                                                                                           text                                                                                                                                                                      text_coda                                                                                                                                                                translated_dict  label\n",
      "0                                                                                                                                                                               Nn mouch 7louwa faza                                                                                                                                                           nn mouch 7louwa faza                                                                                                                                                              Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§                                                                                                                                                              Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§      1\n",
      "1                                                                                                                                                                            mabladkom 3bed tfouuuuh                                                                                                                                                          mabladkom 3bed tfouuh                                                                                                                                                           Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒÙˆÙ… Ø¹Ø¨Ø§Ø¯ ØªÙÙˆÙˆÙ‡                                                                                                                                                           Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡      1\n",
      "2  ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§ØµÙ„Ùƒ Ùˆ Ø¹Ù„Ù‰ ÙØµÙ„Ùƒ Ùˆ Ø¹Ù„Ù‰ Ø§Ù„ÙŠ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¨Ø§Ø´ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§Ù„ÙŠ Ù…ØµÙˆØ­Ø¨Ùƒ Ùˆ Ù…Ø¬Ø§ÙˆØ±Ùƒ Ùˆ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ø±ÙÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø±Ø¶ Ø§Ù„ÙŠ Ù‡Ø§Ø²ØªÙƒ Ùˆ Ø¹Ù„Ù‰ ØªÙˆÙ†Ø³ Ø§Ù„ÙŠ Ù‚Ø§Ø¨Ù„ØªÙƒ ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙ‡  ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ ÙØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¨Ø§Ø´ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ Ù…ØµÙˆØ­Ø¨Ùƒ Ùˆ Ù…Ø¬Ø§ÙˆØ±Ùƒ Ùˆ Ø¹Ù„ÙŠ Ù…Ø¹Ø§Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„Ø§Ø±Ø¶ Ø§Ù„ÙŠ Ù‡Ø§Ø²ØªÙƒ Ùˆ Ø¹Ù„ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„ÙŠ Ù‚Ø§Ø¨Ù„ØªÙƒ ØªÙÙˆÙˆÙ‡  ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ ÙØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¨Ø§Ø´ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ Ù…ØµÙˆØ­Ø¨Ùƒ Ùˆ Ù…Ø¬Ø§ÙˆØ±Ùƒ Ùˆ Ø¹Ù„ÙŠ Ù…Ø¹Ø§Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„Ø§Ø±Ø¶ Ø§Ù„ÙŠ Ù‡Ø§Ø²ØªÙƒ Ùˆ Ø¹Ù„ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„ÙŠ Ù‚Ø§Ø¨Ù„ØªÙƒ ØªÙÙˆÙˆÙ‡  ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ ÙØµÙ„Ùƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¨Ø§Ø´ ÙŠØ¹Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„ÙŠ Ù…ØµÙˆØ­Ø¨Ùƒ Ùˆ Ù…Ø¬Ø§ÙˆØ±Ùƒ Ùˆ Ø¹Ù„ÙŠ Ù…Ø¹Ø§Ø±ÙÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§Ù„Ø§Ø±Ø¶ Ø§Ù„ÙŠ Ù‡Ø§Ø²ØªÙƒ Ùˆ Ø¹Ù„ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„ÙŠ Ù‚Ø§Ø¨Ù„ØªÙƒ ØªÙÙˆÙˆÙ‡      1\n",
      "3                                                                                                                                                                              Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬                                                                                                                                                          Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬                                                                                                                                                          Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬                                                                                                                                                          Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1\n",
      "4                                                                                                                                                                                              Ø±Ù‡Ø¯Ø§Ù†                                                                                                                                                                          Ø±Ù‡Ø¯Ø§Ù†                                                                                                                                                                          Ø±Ù‡Ø¯Ø§Ù†                                                                                                                                                                          Ø±Ù‡Ø¯Ø§Ù†      1\n",
      "5                                                                                                                                                              b rjoulia stoufa to7t men3ini .......                                                                                                                                                b rjoulia stoufa to7t men3ini .                                                                                                                                                   Ø¨ Ø±Ø¬ÙˆÙ„ÙŠØ§ Ø³ØªÙˆÙØ§ ØªÙˆØ­Øª Ù…Ø§Ù†Ø¹Ù†ÙŠ .                                                                                                                                                  Ø¨ Ø±Ø¬ÙˆÙ„ÙŠØ§ Ø³Ø·ÙˆÙØ§ Ø·Ø§Ø­Ø· Ù…Ø§Ù†Ø¹ÙŠÙ†ÙŠ .      1\n",
      "6                                                                                                          Ù‚Ø±Ø¯Ø© Ø¨Ù‡ÙŠÙ…Ø© Ø­Ù…Ø§Ø±Ø© Ø¨ØºÙ„Ø©......... ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ Ø§Ù„Ø® Ø§Ø¨Ø´Ø¹ Ø¹ÙØ§Ù†Ø© Ø´ÙØªÙ‡Ø§ ÙÙŠ Ø­ÙŠØ§ØªÙŠ Ù„Ø§Ø²Ù… ÙŠÙ‚Ø§Ù… Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ø­Ø¯                                                                                              Ù‚Ø±Ø¯Ø© Ø¨Ù‡ÙŠÙ…Ø© Ø­Ù…Ø§Ø±Ø© Ø¨ØºÙ„Ø©. ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ Ø§Ù„Ø® Ø§Ø¨Ø´Ø¹ Ø¹ÙØ§Ù†Ø© Ø´ÙØªÙ‡Ø§ ÙÙŠ Ø­ÙŠØ§ØªÙŠ Ù„Ø§Ø²Ù… ÙŠÙ‚Ø§Ù… Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ø­Ø¯                                                                                              Ù‚Ø±Ø¯Ø© Ø¨Ù‡ÙŠÙ…Ø© Ø­Ù…Ø§Ø±Ø© Ø¨ØºÙ„Ø©. ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ Ø§Ù„Ø® Ø§Ø¨Ø´Ø¹ Ø¹ÙØ§Ù†Ø© Ø´ÙØªÙ‡Ø§ ÙÙŠ Ø­ÙŠØ§ØªÙŠ Ù„Ø§Ø²Ù… ÙŠÙ‚Ø§Ù… Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ø­Ø¯                                                                                              Ù‚Ø±Ø¯Ø© Ø¨Ù‡ÙŠÙ…Ø© Ø­Ù…Ø§Ø±Ø© Ø¨ØºÙ„Ø©. ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ Ø§Ù„Ø® Ø§Ø¨Ø´Ø¹ Ø¹ÙØ§Ù†Ø© Ø´ÙØªÙ‡Ø§ ÙÙŠ Ø­ÙŠØ§ØªÙŠ Ù„Ø§Ø²Ù… ÙŠÙ‚Ø§Ù… Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ø­Ø¯      1\n",
      "7                                                                                                                                  tozzzzzzzzzzzzzzzzzzzz fi 9anet el 7iwaer ettounssi 9anet eda3ara                                                                                                                                tozz fi 9anet el 7iwaer ettounssi 9anet eda3ara                                                                                                                                   ØªÙˆØ²Ø² ÙÙŠ Ù‚Ø§Ù†Ø§Øª Ø§Ù„ Ø­ÙˆØ§Ø§Ø± Ø§ØªØªÙˆÙ†Ø³Ø³ÙŠ Ù‚Ø§Ù†Ø§Øª Ø§Ø¯Ø§Ø¹Ø±Ø§                                                                                                                                 Ø·Ø§Ø²Ø² ÙÙŠ Ù‚Ø§Ù†Ø§Ø· Ø§Ù„ Ø­ÙŠÙˆØ§Ø§Ø± Ø§Ø·Ø·ÙˆÙ†Ø³Ø³ÙŠ Ù‚Ø§Ù†Ø§Ø· Ø§Ø¯Ø§Ø¹Ø§Ø±Ø§      1\n",
      "8                                                                                                                                                                Ø´Ù†ÙˆÙ‰ Ù‡Ø°Ø§ Ø´Ù†ÙŠØ© Ù‡Ø§Ù„Ù…Ø³Ø®Ø±Ø© ØŸØŸØŸØŸØŸØŸØŸØŸØŸØŸØŸØŸ                                                                                                                                                       Ø´Ù†ÙˆÙŠ Ù‡Ø°Ø§ Ø´Ù†ÙŠØ© Ù‡Ø§Ù„Ù…Ø³Ø®Ø±Ø© ?                                                                                                                                                       Ø´Ù†ÙˆÙŠ Ù‡Ø°Ø§ Ø´Ù†ÙŠØ© Ù‡Ø§Ù„Ù…Ø³Ø®Ø±Ø© ?                                                                                                                                                       Ø´Ù†ÙˆÙŠ Ù‡Ø°Ø§ Ø´Ù†ÙŠØ© Ù‡Ø§Ù„Ù…Ø³Ø®Ø±Ø© ?      1\n",
      "9                                                                                                                                                                             Ù…Ø±Ø§ Ù…Ø®ÙŠØ¨ Ø±Ø§Ø³Ùƒ ÙŠØ§ Ù‡Ø§ÙŠØ´Ø©                                                                                                                                                         Ù…Ø±Ø§ Ù…Ø®ÙŠØ¨ Ø±Ø§Ø³Ùƒ ÙŠØ§ Ù‡Ø§ÙŠØ´Ø©                                                                                                                                                         Ù…Ø±Ø§ Ù…Ø®ÙŠØ¨ Ø±Ø§Ø³Ùƒ ÙŠØ§ Ù‡Ø§ÙŠØ´Ø©                                                                                                                                                         Ù…Ø±Ø§ Ù…Ø®ÙŠØ¨ Ø±Ø§Ø³Ùƒ ÙŠØ§ Ù‡Ø§ÙŠØ´Ø©      1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T09:43:19.316338800Z",
     "start_time": "2025-12-26T09:43:19.188208800Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "78d5512fbfcbd38b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   Tweet  label  \\\n",
       "0                                   Nn mouch 7louwa faza      1   \n",
       "1                                mabladkom 3bed tfouuuuh      1   \n",
       "2      ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...      1   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬      1   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†      1   \n",
       "...                                                  ...    ...   \n",
       "47790                                ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢      0   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†      0   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...      0   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§      0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                                   nn mouch 7louwa faza   \n",
       "1                                  mabladkom 3bed tfouuh   \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†   \n",
       "...                                                  ...   \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§   \n",
       "\n",
       "                                         translated_dict  \\\n",
       "0                                      Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§   \n",
       "1                                   Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡   \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...   \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬   \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†   \n",
       "...                                                  ...   \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00   \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†   \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...   \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§   \n",
       "\n",
       "                                               text_coda  \n",
       "0                                      Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§  \n",
       "1                                   Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒÙˆÙ… Ø¹Ø¨Ø§Ø¯ ØªÙÙˆÙˆÙ‡  \n",
       "2      ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...  \n",
       "3                                  Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬  \n",
       "4                                                  Ø±Ù‡Ø¯Ø§Ù†  \n",
       "...                                                  ...  \n",
       "47790                                  ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200  \n",
       "47791                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47792                                        Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†  \n",
       "47793  Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...  \n",
       "47794                                      Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§  \n",
       "\n",
       "[47795 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>translated_dict</th>\n",
       "      <th>text_coda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nn mouch 7louwa faza</td>\n",
       "      <td>1</td>\n",
       "      <td>nn mouch 7louwa faza</td>\n",
       "      <td>Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§</td>\n",
       "      <td>Ù†Ù† Ù…ÙˆØ´ Ø­Ù„ÙˆÙˆØ§ ÙØ§Ø²Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mabladkom 3bed tfouuuuh</td>\n",
       "      <td>1</td>\n",
       "      <td>mabladkom 3bed tfouuh</td>\n",
       "      <td>Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒØ§Ù… Ø¹Ø¨Ø§Ø¯ Ø·ÙÙˆÙˆÙ‡</td>\n",
       "      <td>Ù…Ø§Ø¨Ù„Ø§Ø¯ÙƒÙˆÙ… Ø¹Ø¨Ø§Ø¯ ØªÙÙˆÙˆÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„Ù‰ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„Ù‰ Ø§...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "      <td>ØªÙÙˆÙˆÙ‡ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¹Ù„Ø§ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø¹Ù„ÙŠ Ø¹Ø§ÙŠÙ„ØªÙƒ Ùˆ Ø¹Ù„ÙŠ Ø§ØµÙ„Ùƒ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>1</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "      <td>Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "      <td>Ø±Ù‡Ø¯Ø§Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47790</th>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200ğŸ˜¢ğŸ˜¢</td>\n",
       "      <td>0</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… Ø§00</td>\n",
       "      <td>ÙŠØ§Ø§Ø­Ø³Ø±Ø© Ø§Ù„ÙŠÙˆÙ… 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47791</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47792</th>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47793</th>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙ‰ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„Ù‰ ØªÙˆÙ†...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "      <td>Ø±Ø¨ÙŠ Ø§ÙƒÙˆÙ† ÙÙŠ Ø¹ÙˆÙ†ÙƒÙ… Ø¨Ø§Ù„Ø­Ù‚ Ø±Ø¨ÙŠ Ø§Ø¨Ù‚ÙŠ Ø§Ù„Ø³ØªØ± Ø¹Ù„ÙŠ ØªÙˆÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47794</th>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "      <td>Ø±Ø¨ÙŠ ÙŠÙ„Ø·Ù Ø¨ÙŠÙ†Ø§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47795 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:48.614228500Z",
     "start_time": "2025-12-26T10:24:31.888596100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Any, Dict\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERT\")\n",
    "\n",
    "# token length stats on *CODA-transliterated* text\n",
    "lengths = [len(tokenizer(t, add_special_tokens=True).input_ids) for t in df[\"text_coda\"]]\n",
    "percentiles = np.percentile(lengths, [50, 75, 90, 95, 99])\n",
    "print(f\"Token Length Percentiles (50, 75, 90, 95, 99): {percentiles}\")\n"
   ],
   "id": "55ad96ebbc46cbc6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Length Percentiles (50, 75, 90, 95, 99): [ 9. 14. 25. 35. 76.]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:51.017176700Z",
     "start_time": "2025-12-26T10:24:50.932708400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show tokenization as tokens (strings), not only IDs\n",
    "sample = df.loc[3, \"text_coda\"]\n",
    "\n",
    "tokens = tokenizer.tokenize(sample)\n",
    "encoded: Dict[str, Any] = tokenizer(sample, add_special_tokens=True)\n",
    "\n",
    "tokens_with_special = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "\n",
    "print(\"TEXT:\", sample)\n",
    "print(\"\\nTOKENS (no special tokens):\")\n",
    "print(tokens)\n",
    "print(\"\\nTOKENS (with special tokens):\")\n",
    "print(tokens_with_special)\n"
   ],
   "id": "c24ddece8c5f74bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Ù„Ø§ ÙŠÙ„ÙŠÙ‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬\n",
      "\n",
      "TOKENS (no special tokens):\n",
      "['Ù„Ø§', 'ÙŠÙ„ÙŠÙ‚', 'Ø¨Ù‡Ø°Ø§', 'Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬']\n",
      "\n",
      "TOKENS (with special tokens):\n",
      "['[CLS]', 'Ù„Ø§', 'ÙŠÙ„ÙŠÙ‚', 'Ø¨Ù‡Ø°Ø§', 'Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬', '[SEP]']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:53.835314400Z",
     "start_time": "2025-12-26T10:24:53.730373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 3 â€” Dataset Preparation\n",
    "# ========================================================================\n",
    "# Merge Arabizi and Arabic text into a single dataset for training.\n",
    "# This doubles the size of our dataset, providing more examples for the model.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create two dataframes: one with preprocessed Arabizi, one with CODA-translated Arabic\n",
    "df_arabizi = df[['text', 'label']].copy()\n",
    "df_arabic = df[['text_coda', 'label']].copy()\n",
    "\n",
    "# Rename column for consistency\n",
    "df_arabic.rename(columns={'text_coda': 'text'}, inplace=True)\n",
    "\n",
    "# Combine the two dataframes\n",
    "merged_df = pd.concat([df_arabizi, df_arabic], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"Merged and augmented dataset size:\", len(merged_df))\n"
   ],
   "id": "2843503213aef76f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 47795\n",
      "Merged and augmented dataset size: 95590\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:24:57.848440Z",
     "start_time": "2025-12-26T10:24:57.708772600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# Dataset Split (Train / Validation / Test)\n",
    "# ========================================================================\n",
    "# We'll use a stratified split to maintain the same class distribution\n",
    "# across the train, validation, and test sets.\n",
    "\n",
    "# Split into 80% train, 20% temporary (for val/test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    merged_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=merged_df['label']\n",
    ")\n",
    "\n",
    "# Split the temporary set into 50% validation, 50% test (10% of total each)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "# ========================================================================\n",
    "# BALANCE TRAINING SET (Undersampling)\n",
    "# ========================================================================\n",
    "# The dataset is imbalanced (approx 74% class 0, 26% class 1).\n",
    "# We balance the TRAINING set to prevent bias/overfitting to the majority class.\n",
    "# We keep Validation and Test sets with the original distribution to reflect reality.\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes in training set\n",
    "train_majority = train_df[train_df.label == 0]\n",
    "train_minority = train_df[train_df.label == 1]\n",
    "\n",
    "# Undersample majority class\n",
    "train_majority_downsampled = resample(train_majority,\n",
    "                                      replace=False,    # sample without replacement\n",
    "                                      n_samples=len(train_minority), # match minority n\n",
    "                                      random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "train_df = pd.concat([train_majority_downsampled, train_minority])\n",
    "\n",
    "# Shuffle the balanced training set\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train set size (Balanced): {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n"
   ],
   "id": "4f009251bbd24521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size (Balanced): 40180\n",
      "Validation set size: 9559\n",
      "Test set size: 9559\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:25:01.200461500Z",
     "start_time": "2025-12-26T10:25:01.126796600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# Verify Class Balance in Each Split\n",
    "# ========================================================================\n",
    "# It's crucial to check that the label distribution is similar across all sets\n",
    "# to ensure the model is evaluated fairly.\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate and display normalized distribution for each set\n",
    "train_dist = train_df['label'].value_counts(normalize=True).sort_index()\n",
    "val_dist = val_df['label'].value_counts(normalize=True).sort_index()\n",
    "test_dist = test_df['label'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "distribution_df = pd.DataFrame({\n",
    "    'Train': train_dist,\n",
    "    'Validation': val_dist,\n",
    "    'Test': test_dist\n",
    "})\n",
    "\n",
    "print(distribution_df.to_string(float_format=\"%.2f\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASS COUNTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTrain set label counts:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nValidation set label counts:\")\n",
    "print(val_df['label'].value_counts())\n",
    "print(\"\\nTest set label counts:\")\n",
    "print(test_df['label'].value_counts())\n",
    "\n"
   ],
   "id": "2b426d1d6e63988f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLASS DISTRIBUTION\n",
      "==================================================\n",
      "       Train  Validation  Test\n",
      "label                         \n",
      "0       0.50        0.74  0.74\n",
      "1       0.50        0.26  0.26\n",
      "\n",
      "==================================================\n",
      "CLASS COUNTS\n",
      "==================================================\n",
      "\n",
      "Train set label counts:\n",
      "label\n",
      "0    20090\n",
      "1    20090\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set label counts:\n",
      "label\n",
      "0    7048\n",
      "1    2511\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label counts:\n",
      "label\n",
      "0    7048\n",
      "1    2511\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:25:15.660252300Z",
     "start_time": "2025-12-26T10:25:06.774947900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 4 â€” Tokenization\n",
    "# ========================================================================\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize MARBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERT\")\n",
    "\n",
    "def tokenize_dataset(df, tokenizer, max_length=64):\n",
    "    \"\"\"\n",
    "    Tokenize the text column of a dataframe.\n",
    "    Returns input_ids and attention_mask as PyTorch tensors.\n",
    "    \"\"\"\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return encodings\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "\n",
    "# Tokenize each split\n",
    "train_encodings = tokenize_dataset(train_df, tokenizer)\n",
    "val_encodings = tokenize_dataset(val_df, tokenizer)\n",
    "test_encodings = tokenize_dataset(test_df, tokenizer)\n",
    "\n",
    "# Extract labels as tensors\n",
    "train_labels = torch.tensor(train_df['label'].tolist())\n",
    "val_labels = torch.tensor(val_df['label'].tolist())\n",
    "test_labels = torch.tensor(test_df['label'].tolist())\n",
    "\n",
    "print(\"\\nTokenization Complete.\")\n",
    "print(f\"Train encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Validation encodings shape: {val_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample Tokenization (First Train Example):\")\n",
    "print(f\"Text: {train_df.iloc[0]['text']}\")\n",
    "print(f\"Input IDs: {train_encodings['input_ids'][0]}\")\n",
    "print(f\"Attention Mask: {train_encodings['attention_mask'][0]}\")\n",
    "print(f\"Label: {train_labels[0]}\")\n"
   ],
   "id": "1b29d323e2ee1525",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n",
      "\n",
      "Tokenization Complete.\n",
      "Train encodings shape: torch.Size([40180, 64])\n",
      "Validation encodings shape: torch.Size([9559, 64])\n",
      "Test encodings shape: torch.Size([9559, 64])\n",
      "\n",
      "Sample Tokenization (First Train Example):\n",
      "Text: Ø­Ù„ ÙÙ…Ùƒ Ù‚ÙˆÙ„ Ø§Ù„Ù†Ø§Ø³ ØªØ´Ø¯ Ø¯ÙŠØ§Ø±Ù‡Ø§\n",
      "Input IDs: tensor([    2,  4302, 17113,  3271,  2195, 25533, 80606,  1011,     3,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:25:53.494127700Z",
     "start_time": "2025-12-26T10:25:45.940120500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 5 â€” Model Setup\n",
    "# ========================================================================\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load MARBERT model for sequence classification\n",
    "print(\"Loading MARBERT model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"UBC-NLP/MARBERT\",\n",
    "    num_labels=2,\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully and moved to device.\")\n"
   ],
   "id": "779370f144c6e8bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading MARBERT model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5063ecc5ee214413bdbba22dbc7a64aa"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: UBC-NLP/MARBERT\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and moved to device.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:27:34.846424300Z",
     "start_time": "2025-12-26T10:27:34.743769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 6 â€” Training\n",
    "# ========================================================================\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create Custom Dataset Class\n",
    "class TunisianDialectDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 2. Create DataLoaders\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = TunisianDialectDataset(train_encodings, train_labels)\n",
    "val_dataset = TunisianDialectDataset(val_encodings, val_labels)\n",
    "test_dataset = TunisianDialectDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "print(f\"DataLoaders created with batch size {batch_size}\")"
   ],
   "id": "4169faabc60f6332",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created with batch size 16\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:21:50.330197300Z",
     "start_time": "2025-12-26T09:53:51.928481900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 6 â€” Training\n",
    "# ========================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Define Optimizer and Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "epochs = 3\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# 4. Training Loop\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.set_postfix({'loss': np.mean(losses)})\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "# Training Execution\n",
    "print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler\n",
    "    )\n",
    "\n",
    "    print(f\"Train loss {train_loss:.4f} accuracy {train_acc:.4f}\")\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(f\"Val   loss {val_loss:.4f} accuracy {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_accuracy:\n",
    "        print(f\"Validation accuracy improved from {best_accuracy:.4f} to {val_acc:.4f}. Saving model...\")\n",
    "        model.save_pretrained(\"best_tunisian_model\")\n",
    "        tokenizer.save_pretrained(\"best_tunisian_model\")\n",
    "        best_accuracy = val_acc\n",
    "\n",
    "print(\"\\nTraining complete!\")\n"
   ],
   "id": "d75fed4c27a7cc1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created with batch size 16\n",
      "\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/2512 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7251e86dde3e46058f63dbdbc55a4049"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3329 accuracy 0.8568\n",
      "Val   loss 0.2457 accuracy 0.9217\n",
      "Validation accuracy improved from 0.0000 to 0.9217. Saving model...\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/2512 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "085b0c7be14e49959fad11835287d684"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:29:23.232003100Z",
     "start_time": "2025-12-26T10:27:39.467449200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================================================\n",
    "# PHASE 7 â€” Evaluation\n",
    "# ========================================================================\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load Saved Model\n",
    "print(\"Loading best saved model...\")\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"best_tunisian_model\")\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# 2. Run Inference on Test Set\n",
    "print(\"Running inference on test set...\")\n",
    "\n",
    "def get_predictions(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            real_values.extend(labels.cpu().tolist())\n",
    "\n",
    "    return predictions, real_values\n",
    "\n",
    "y_pred, y_test = get_predictions(loaded_model, test_loader, device)\n",
    "\n",
    "# 3. Compute Metrics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative (0)', 'Positive (1)']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Optional: Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "id": "7a21bc00717f020e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best saved model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82513efbe2e4452796d3662111a0e913"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/598 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c67df4f5d20d476ca8afec6a49f5aab9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEST SET RESULTS\n",
      "==================================================\n",
      "Accuracy: 0.9200\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)       0.97      0.92      0.94      7048\n",
      "Positive (1)       0.81      0.92      0.86      2511\n",
      "\n",
      "    accuracy                           0.92      9559\n",
      "   macro avg       0.89      0.92      0.90      9559\n",
      "weighted avg       0.93      0.92      0.92      9559\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6490  558]\n",
      " [ 207 2304]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T10:44:41.534460400Z",
     "start_time": "2025-12-26T10:44:41.302898600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_sentiment(text, model, tokenizer, device):\n",
    "    # 1. Preprocess the text (using the function defined in Phase 1)\n",
    "    cleaned_text = preprocess_text(text)\n",
    "\n",
    "    # 2. Tokenize\n",
    "    inputs = tokenizer(\n",
    "        cleaned_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    ).to(device)\n",
    "\n",
    "    # 3. Run Inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Apply Softmax to get probabilities (0 to 1)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "        # Get the predicted class (0 or 1) and the confidence score\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_idx].item()\n",
    "\n",
    "    # 4. Map to Label\n",
    "    # Assuming 0 = Negative, 1 = Positive based on your classification report\n",
    "    labels = {1: \"Negative\",0: \"Positive\"}\n",
    "\n",
    "    return labels[pred_idx], confidence\n",
    "\n",
    "# --- Test the specific sentence ---\n",
    "sentence = \"zeyed ga3bout w matjich rajel\"\n",
    "\n",
    "# Predict on raw Arabizi\n",
    "label, score = predict_sentiment(sentence, loaded_model, tokenizer, device)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Input Text:  {sentence}\")\n",
    "print(f\"Prediction:  {label}\")\n",
    "print(f\"Confidence:  {score:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "transliterated = transliterator.transliterate_text(sentence, use_vocab_matching=True)\n",
    "label_ar, score_ar = predict_sentiment(transliterated, loaded_model, tokenizer, device)\n",
    "\n",
    "print(f\"Transliterated: {transliterated}\")\n",
    "print(f\"Prediction (Ar): {label_ar} ({score_ar:.4f})\")\n",
    "print(\"-\" * 30)"
   ],
   "id": "21095eadcccabb96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Input Text:  zeyed ga3bout w matjich rajel\n",
      "Prediction:  Negative\n",
      "Confidence:  0.7177\n",
      "------------------------------\n",
      "Transliterated: Ø§ÙŠØ§Ø¯ Ù‚Ø§Ø±Ø¨Øª Ùˆ Ù…Ø§ØªØ¬ÙŠÙˆØ´ Ø±Ø¬Ø§Ù„\n",
      "Prediction (Ar): Negative (0.9721)\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2605b8d68eb4fc2c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
